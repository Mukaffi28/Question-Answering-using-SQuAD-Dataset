{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1133655,"sourceType":"datasetVersion","datasetId":633717}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install evaluate\n!pip install rouge\n\n\nimport torch\nimport json\nfrom tqdm import tqdm\nimport torch.nn as nn\nfrom torch.optim import Adam\nimport nltk\nimport spacy\nimport string\nimport evaluate  # Bleu\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler\nimport pandas as pd\nimport numpy as np\nimport transformers\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-05T15:26:47.016821Z","iopub.execute_input":"2024-02-05T15:26:47.017560Z","iopub.status.idle":"2024-02-05T15:27:49.956098Z","shell.execute_reply.started":"2024-02-05T15:26:47.017523Z","shell.execute_reply":"2024-02-05T15:27:49.955201Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.37.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.12.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\nCollecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n","output_type":"stream"},{"name":"stderr","text":"2024-02-05 15:27:37.873526: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-05 15:27:37.873622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-05 15:27:38.041059: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"TOKENIZER = T5TokenizerFast.from_pretrained(\"t5-base\")\nMODEL = T5ForConditionalGeneration.from_pretrained(\"t5-base\", return_dict=True)\nOPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\nQ_LEN = 256   # Question Length\nT_LEN = 32    # Target Length\nBATCH_SIZE = 4\nDEVICE = \"cuda:0\"","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:27:49.957737Z","iopub.execute_input":"2024-02-05T15:27:49.958499Z","iopub.status.idle":"2024-02-05T15:27:55.707933Z","shell.execute_reply.started":"2024-02-05T15:27:49.958471Z","shell.execute_reply":"2024-02-05T15:27:55.707218Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b73da10b4c5c47769a280d986b9d7ee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59bf702b1f8548b9845856758ca24e4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"969fc4d12a604f9abb77abf64368e9cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f97a89df203e4fb79674485a5f673ddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a99f9be94e54fd897d3867bca0a2ae1"}},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/squad-v11/SQuAD-v1.1.csv\")\ndf\n","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:27:55.709097Z","iopub.execute_input":"2024-02-05T15:27:55.709358Z","iopub.status.idle":"2024-02-05T15:27:57.308139Z","shell.execute_reply.started":"2024-02-05T15:27:55.709335Z","shell.execute_reply":"2024-02-05T15:27:57.307172Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                          title  \\\n0      University_of_Notre_Dame   \n1      University_of_Notre_Dame   \n2      University_of_Notre_Dame   \n3      University_of_Notre_Dame   \n4      University_of_Notre_Dame   \n...                         ...   \n87594                 Kathmandu   \n87595                 Kathmandu   \n87596                 Kathmandu   \n87597                 Kathmandu   \n87598                 Kathmandu   \n\n                                                 context  \\\n0      Architecturally, the school has a Catholic cha...   \n1      Architecturally, the school has a Catholic cha...   \n2      Architecturally, the school has a Catholic cha...   \n3      Architecturally, the school has a Catholic cha...   \n4      Architecturally, the school has a Catholic cha...   \n...                                                  ...   \n87594  Kathmandu Metropolitan City (KMC), in order to...   \n87595  Kathmandu Metropolitan City (KMC), in order to...   \n87596  Kathmandu Metropolitan City (KMC), in order to...   \n87597  Kathmandu Metropolitan City (KMC), in order to...   \n87598  Kathmandu Metropolitan City (KMC), in order to...   \n\n                                                question  \\\n0      To whom did the Virgin Mary allegedly appear i...   \n1      What is in front of the Notre Dame Main Building?   \n2      The Basilica of the Sacred heart at Notre Dame...   \n3                      What is the Grotto at Notre Dame?   \n4      What sits on top of the Main Building at Notre...   \n...                                                  ...   \n87594  In what US state did Kathmandu first establish...   \n87595               What was Yangon previously known as?   \n87596  With what Belorussian city does Kathmandu have...   \n87597  In what year did Kathmandu create its initial ...   \n87598                      What is KMC an initialism of?   \n\n                                        answer  answer_start  answer_end  \n0                   Saint Bernadette Soubirous           515         541  \n1                    a copper statue of Christ           188         213  \n2                            the Main Building           279         296  \n3      a Marian place of prayer and reflection           381         420  \n4           a golden statue of the Virgin Mary            92         126  \n...                                        ...           ...         ...  \n87594                                   Oregon           229         235  \n87595                                  Rangoon           414         421  \n87596                                    Minsk           476         481  \n87597                                     1975           199         203  \n87598              Kathmandu Metropolitan City             0          27  \n\n[87599 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>To whom did the Virgin Mary allegedly appear i...</td>\n      <td>Saint Bernadette Soubirous</td>\n      <td>515</td>\n      <td>541</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What is in front of the Notre Dame Main Building?</td>\n      <td>a copper statue of Christ</td>\n      <td>188</td>\n      <td>213</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n      <td>the Main Building</td>\n      <td>279</td>\n      <td>296</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What is the Grotto at Notre Dame?</td>\n      <td>a Marian place of prayer and reflection</td>\n      <td>381</td>\n      <td>420</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What sits on top of the Main Building at Notre...</td>\n      <td>a golden statue of the Virgin Mary</td>\n      <td>92</td>\n      <td>126</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87594</th>\n      <td>Kathmandu</td>\n      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n      <td>In what US state did Kathmandu first establish...</td>\n      <td>Oregon</td>\n      <td>229</td>\n      <td>235</td>\n    </tr>\n    <tr>\n      <th>87595</th>\n      <td>Kathmandu</td>\n      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n      <td>What was Yangon previously known as?</td>\n      <td>Rangoon</td>\n      <td>414</td>\n      <td>421</td>\n    </tr>\n    <tr>\n      <th>87596</th>\n      <td>Kathmandu</td>\n      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n      <td>With what Belorussian city does Kathmandu have...</td>\n      <td>Minsk</td>\n      <td>476</td>\n      <td>481</td>\n    </tr>\n    <tr>\n      <th>87597</th>\n      <td>Kathmandu</td>\n      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n      <td>In what year did Kathmandu create its initial ...</td>\n      <td>1975</td>\n      <td>199</td>\n      <td>203</td>\n    </tr>\n    <tr>\n      <th>87598</th>\n      <td>Kathmandu</td>\n      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n      <td>What is KMC an initialism of?</td>\n      <td>Kathmandu Metropolitan City</td>\n      <td>0</td>\n      <td>27</td>\n    </tr>\n  </tbody>\n</table>\n<p>87599 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\nselected_columns = [\"context\", \"question\", \"answer\"]\ndf = df[selected_columns]","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:27:57.311316Z","iopub.execute_input":"2024-02-05T15:27:57.311938Z","iopub.status.idle":"2024-02-05T15:27:57.322071Z","shell.execute_reply.started":"2024-02-05T15:27:57.311897Z","shell.execute_reply":"2024-02-05T15:27:57.321218Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df=df[:8000]","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:27:57.323307Z","iopub.execute_input":"2024-02-05T15:27:57.323627Z","iopub.status.idle":"2024-02-05T15:27:57.349208Z","shell.execute_reply.started":"2024-02-05T15:27:57.323594Z","shell.execute_reply":"2024-02-05T15:27:57.348339Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class QA_Dataset(Dataset):\n    def __init__(self, tokenizer, dataframe, q_len, t_len):\n        self.tokenizer = tokenizer\n        self.q_len = q_len\n        self.t_len = t_len\n        self.data = dataframe\n        self.questions = self.data[\"question\"]\n        self.context = self.data[\"context\"]\n        self.answer = self.data[\"answer\"]\n        \n    def __len__(self):\n        return len(self.questions)\n    \n    def __getitem__(self, idx):\n        if idx < 0 or idx >= len(self.questions):\n            raise IndexError(f\"Index {idx} is out of bounds for the dataset.\")\n        question = self.questions[idx]\n        context = self.context[idx]\n        answer = self.answer[idx]\n        \n        question_tokenized = self.tokenizer(question, context, max_length=self.q_len, padding=\"max_length\",\n                                                    truncation=True, pad_to_max_length=True, add_special_tokens=True)\n        answer_tokenized = self.tokenizer(answer, max_length=self.t_len, padding=\"max_length\", \n                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n        \n        labels = torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long)\n        labels[labels == 0] = -100\n        \n        return {\n            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n            \"labels\": labels,\n            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:30:45.144624Z","iopub.execute_input":"2024-02-05T15:30:45.145358Z","iopub.status.idle":"2024-02-05T15:30:45.155479Z","shell.execute_reply.started":"2024-02-05T15:30:45.145318Z","shell.execute_reply":"2024-02-05T15:30:45.154534Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Dataloader\n\ntrain_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n\n# Get the indices of the DataFrames\ntrain_indices = train_data.index.tolist()\nval_indices = val_data.index.tolist()\n\n# Create RandomSamplers using the indices\ntrain_sampler = RandomSampler(train_indices)\nval_sampler = RandomSampler(val_indices)\n\nqa_dataset = QA_Dataset(TOKENIZER, df, Q_LEN, T_LEN)\n\ntrain_loader = DataLoader(qa_dataset, batch_size=20, sampler=train_sampler)\nval_loader = DataLoader(qa_dataset, batch_size=20, sampler=val_sampler)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:30:46.456134Z","iopub.execute_input":"2024-02-05T15:30:46.456755Z","iopub.status.idle":"2024-02-05T15:30:46.467476Z","shell.execute_reply.started":"2024-02-05T15:30:46.456726Z","shell.execute_reply":"2024-02-05T15:30:46.466647Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Move the model to the same device if it's not already\nMODEL = MODEL.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:30:47.544718Z","iopub.execute_input":"2024-02-05T15:30:47.545082Z","iopub.status.idle":"2024-02-05T15:30:47.926813Z","shell.execute_reply.started":"2024-02-05T15:30:47.545057Z","shell.execute_reply":"2024-02-05T15:30:47.925812Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_loss = 0\nval_loss = 0\ntrain_batch_count = 0\nval_batch_count = 0\n\nfor epoch in range(20):\n    MODEL.train()\n    for batch in tqdm(train_loader, desc=\"Training batches\"):\n        input_ids = batch[\"input_ids\"].to(DEVICE)\n        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n        labels = batch[\"labels\"].to(DEVICE)\n        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n\n        outputs = MODEL(\n                          input_ids=input_ids,\n                          attention_mask=attention_mask,\n                          labels=labels,\n                          decoder_attention_mask=decoder_attention_mask\n                        )\n\n        OPTIMIZER.zero_grad()\n        outputs.loss.backward()\n        OPTIMIZER.step()\n        train_loss += outputs.loss.item()\n        train_batch_count += 1\n    \n    #Evaluation\n    MODEL.eval()\n    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n        input_ids = batch[\"input_ids\"].to(DEVICE)\n        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n        labels = batch[\"labels\"].to(DEVICE)\n        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n\n        outputs = MODEL(\n                          input_ids=input_ids,\n                          attention_mask=attention_mask,\n                          labels=labels,\n                          decoder_attention_mask=decoder_attention_mask\n                        )\n\n        OPTIMIZER.zero_grad()\n        outputs.loss.backward()\n        OPTIMIZER.step()\n        val_loss += outputs.loss.item()\n        val_batch_count += 1\n        \n    print(f\"{epoch+1}/{20} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:30:48.800807Z","iopub.execute_input":"2024-02-05T15:30:48.801810Z","iopub.status.idle":"2024-02-05T17:03:56.598204Z","shell.execute_reply.started":"2024-02-05T15:30:48.801775Z","shell.execute_reply":"2024-02-05T17:03:56.597269Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:45<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"1/20 -> Train loss: 1.9833295404911042\tValidation loss: 0.7666220560669899\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"2/20 -> Train loss: 1.2898366898298264\tValidation loss: 0.5625027752947063\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"3/20 -> Train loss: 0.9963923059248676\tValidation loss: 0.4627503800516327\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"4/20 -> Train loss: 0.8349140839127358\tValidation loss: 0.4001928806188516\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"5/20 -> Train loss: 0.7318453164026141\tValidation loss: 0.3553768846066669\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"6/20 -> Train loss: 0.6579105808710058\tValidation loss: 0.320658737514168\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"7/20 -> Train loss: 0.60052766638941\tValidation loss: 0.2932661844084838\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"8/20 -> Train loss: 0.5559711159323342\tValidation loss: 0.27044888896343766\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"9/20 -> Train loss: 0.5194112801174116\tValidation loss: 0.25106152777637664\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"10/20 -> Train loss: 0.4884010719449725\tValidation loss: 0.2344073460472282\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"11/20 -> Train loss: 0.46183824891711334\tValidation loss: 0.22000330240698532\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"12/20 -> Train loss: 0.4386711457404696\tValidation loss: 0.20705602573192058\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"13/20 -> Train loss: 0.4178405742778873\tValidation loss: 0.19553708884363563\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.43it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"14/20 -> Train loss: 0.3994108837126987\tValidation loss: 0.1851660078148208\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.43it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"15/20 -> Train loss: 0.3829889475934518\tValidation loss: 0.1758473947510356\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.43it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"16/20 -> Train loss: 0.36800854487210016\tValidation loss: 0.16727515068614593\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.43it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"17/20 -> Train loss: 0.35433572971053173\tValidation loss: 0.15947384606843115\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.43it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"18/20 -> Train loss: 0.3419055717851734\tValidation loss: 0.15233039504358506\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"19/20 -> Train loss: 0.33044844371018517\tValidation loss: 0.14574570566496972\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 320/320 [03:44<00:00,  1.42it/s]\nValidation batches: 100%|██████████| 80/80 [00:54<00:00,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"20/20 -> Train loss: 0.31962701897355145\tValidation loss: 0.13967859704272997\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict_answer(context, question, ref_answer=None):\n    inputs = TOKENIZER(question, context, max_length=Q_LEN, padding=\"max_length\", truncation=True, add_special_tokens=True)\n    \n    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n\n    outputs = MODEL.generate(input_ids=input_ids, attention_mask=attention_mask)\n  \n    predicted_answer = TOKENIZER.decode(outputs.flatten(), skip_special_tokens=True)\n    \n    if ref_answer:\n        # Load the Bleu metric\n        bleu = evaluate.load(\"google_bleu\")\n        score = bleu.compute(predictions=[predicted_answer], \n                            references=[ref_answer])\n    \n        print(\"Context: \\n\", context)\n        print(\"\\n\")\n        print(\"Question: \\n\", question)\n        return {\n            \"Reference Answer: \": ref_answer, \n            \"Predicted Answer: \": predicted_answer, \n            \"BLEU Score: \": score\n        }\n    else:\n        return predicted_answer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}